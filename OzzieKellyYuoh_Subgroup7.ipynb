{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv('cluster_7.csv')\n",
    "y = df['Bankrupt?']\n",
    "X = df.drop(columns=['Bankrupt?','Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = X.corr()\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr.iloc[i, j]) > 0.75:\n",
    "            column_to_drop = corr.columns[i]\n",
    "            if column_to_drop in X.columns:\n",
    "                X = X.drop(columns=column_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled_df = X_scaled_df.loc[:, X_scaled_df.std() != 0]\n",
    "X = X_scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([' Operating Gross Margin', ' Operating Expense Rate', ' Cash flow rate',\n",
      "       ' Net Value Per Share (B)', ' Current Ratio', ' Quick Ratio',\n",
      "       ' Interest Expense Ratio', ' Total debt/Total net worth',\n",
      "       ' Total expense/Assets', ' Quick Asset Turnover Rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features='auto', random_state=42)\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'MI': mi_scores})\n",
    "selected_features = mi_df[mi_df['MI'] > .02]['Feature'].tolist()\n",
    "X = X[selected_features]\n",
    "\n",
    "columns = X.columns\n",
    "\n",
    "print(columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FeatureSelector7(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        \"\"\"\n",
    "        Initialize the feature selector with the column names to be selected.\n",
    "        \n",
    "        :param columns: List of column names to select from the DataFrame.\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.scaler = StandardScaler()  # Create a scaler object\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the scaler on the selected columns.\n",
    "        \"\"\"\n",
    "        # Select only the columns specified by the user\n",
    "        X_selected = X[self.columns]\n",
    "        # Fit the scaler only on the selected columns\n",
    "        self.scaler.fit(X_selected)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Select the specified columns and scale them.\n",
    "        \n",
    "        :param X: Input DataFrame.\n",
    "        :return: Scaled DataFrame with selected columns.\n",
    "        \"\"\"\n",
    "        # Select only the columns specified by the user\n",
    "        X_selected = X[self.columns]\n",
    "        # Scale the selected columns\n",
    "        X_scaled = self.scaler.transform(X_selected)\n",
    "        \n",
    "        # Create a DataFrame with the scaled columns and original column names\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=self.columns, index=X.index)\n",
    "        return X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy: 1.0\n",
      "dt accuracy: 1.0\n",
      "hgb accuracy: 1.0\n",
      "cv: 0.976\n",
      "Confusion Matrix:\n",
      "------------------------------------\n",
      " [[319  10]\n",
      " [  0  85]]\n",
      "\n",
      "Classification Report:\n",
      "------------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       329\n",
      "           1       0.89      1.00      0.94        85\n",
      "\n",
      "    accuracy                           0.98       414\n",
      "   macro avg       0.95      0.98      0.96       414\n",
      "weighted avg       0.98      0.98      0.98       414\n",
      "\n",
      "rf:\n",
      "TT: 85\n",
      "TF: 0\n",
      "acc: 1.0\n",
      "\n",
      "dt:\n",
      "TT: 85\n",
      "TF: 0\n",
      "acc: 1.0\n",
      "\n",
      "hgb:\n",
      "TT: 85\n",
      "TF: 0\n",
      "acc: 1.0\n",
      "\n",
      "\n",
      "Meta model - TT:\n",
      "TT: 85\n",
      "TF: 0\n",
      "acc: 1.0\n",
      "\n",
      "n_features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "base_models = [\n",
    "    #('knn',KNeighborsClassifier(weights='uniform',n_neighbors=1,metric='manhattan')),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced',max_depth=17,min_samples_split=3,min_samples_leaf=2,random_state=100)),\n",
    "    #('svc', SVC(class_weight='balanced',C=1,gamma=1)),  \n",
    "    ('dt', DecisionTreeClassifier(class_weight='balanced',random_state=100,max_depth=17,min_samples_split=2,min_samples_leaf=1,criterion='entropy')),\n",
    "    #('gpc', GaussianProcessClassifier()),\n",
    "    ('hgb', HistGradientBoostingClassifier(class_weight='balanced',random_state=100,max_depth=6,learning_rate=.1,l2_regularization=4,min_samples_leaf=10, max_leaf_nodes=None,early_stopping=False))\n",
    "\n",
    "]\n",
    "for name, model in base_models:\n",
    "    model.fit(X, y)\n",
    "    score = model.score(X, y)\n",
    "    print(f'{name} accuracy: {round(score, 3)}')\n",
    "\n",
    "meta_model = LogisticRegression(class_weight='balanced', solver='liblinear',C=.3,penalty='l2',random_state=100)\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "result = stacked_model.fit(X,y).score(X,y)\n",
    "print(f'cv: {round(result,3)}') \n",
    "\n",
    "y_pred = stacked_model.predict(X)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix:\\n------------------------------------\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n------------------------------------\\n\", classification_report(y, y_pred))\n",
    "\n",
    "for name, model in base_models:\n",
    "    y_pred = model.predict(X)\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    TT = conf_matrix[1, 1] \n",
    "    TF = conf_matrix[1, 0] \n",
    "\n",
    "    if (TT+TF) != 0:\n",
    "        ratio = TT / (TT+TF)\n",
    "    else:\n",
    "        ratio = 1\n",
    "    \n",
    "    print(f\"{name}:\\nTT: {TT}\\nTF: {TF}\\nacc: {ratio}\\n\")\n",
    "\n",
    "y_pred_meta = stacked_model.predict(X)\n",
    "conf_matrix = confusion_matrix(y, y_pred_meta)\n",
    "TT = conf_matrix[1, 1]\n",
    "TF = conf_matrix[1, 0]\n",
    "ratio = TT / (TT+ TF)\n",
    "print(f\"\\nMeta model - TT:\\nTT: {TT}\\nTF: {TF}\\nacc: {ratio}\\n\")\n",
    "print(f\"n_features: {len(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('feature_select', FeatureSelector7(columns)),  # Feature selection step\n",
    "    ('model', stacked_model)  # Stacking model\n",
    "])\n",
    "\n",
    "print(pipeline) \n",
    "\n",
    "y = df['Bankrupt?']\n",
    "X = df.drop(columns=['Bankrupt?','Index'])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "joblib.dump(pipeline, 'subgroup_7_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
